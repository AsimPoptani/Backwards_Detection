{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import movie_images_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainning_folder=\"trainning_images\"\n",
    "test_folder=\"test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainning_data_set=[]\n",
    "test_data_set=[]\n",
    "# Loop through trainning images\n",
    "for index in range(3):\n",
    "    trainning_data_set.append(pd.DataFrame(movie_images_to_dict.get_images_to_dict(f'/media/Data/backwards_detection/trainning_images/{index}/')).to_numpy())\n",
    "# Loop through test images\n",
    "for index in range(1):\n",
    "    test_data_set.append(pd.DataFrame(movie_images_to_dict.get_images_to_dict(f'/media/Data/backwards_detection/test_images/{index}/')).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trainning_data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "def shape(ndarray: Union[List, float]) -> Tuple[int, ...]:\n",
    "    if isinstance(ndarray, list):\n",
    "        # More dimensions, so make a recursive call\n",
    "        outermost_size = len(ndarray)\n",
    "        row_shape = shape(ndarray[0])\n",
    "        return (outermost_size, *row_shape)\n",
    "    else:\n",
    "        # No more dimensions, so we're done\n",
    "        return ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion methods \n",
    "# will generate a array of x frames\n",
    "def every_x_frame(data,x=5):\n",
    "    size=data.shape[0]\n",
    "    left_over=size%x\n",
    "    n_times=math.floor(size/x)\n",
    "    data=data[:-left_over,:]\n",
    "    split=np.split(data,n_times)\n",
    "    return split\n",
    "\n",
    "def negative_frames(data,x):\n",
    "    data_to_be_shuffled=data.copy()\n",
    "    \n",
    "    np.random.shuffle(data_to_be_shuffled)\n",
    "    random=every_x_frame(data_to_be_shuffled,x)\n",
    "    flip=every_x_frame(np.flip(data,axis=0),x)\n",
    "    return flip+random\n",
    "\n",
    "# generates positive and negative tests for x frames\n",
    "def gen_every_x_frames(data,x=5):\n",
    "    data=data.copy()\n",
    "    positive=every_x_frame(data,x)\n",
    "    negative=negative_frames(data,x)\n",
    "    return [positive,negative]\n",
    "\n",
    "# generates positive and negative tests for x frames\n",
    "def gen_every_x_frames_skip(data,step=2,x=5):\n",
    "    data=data.copy()\n",
    "    data=data[::step]\n",
    "    return gen_every_x_frames(data,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_IMAGES=5\n",
    "def trainning_data_set_gen():\n",
    "    data_set_pos=[]\n",
    "    data_set_neg=[]\n",
    "    for trainning in trainning_data_set:\n",
    "        # generate cases for NUMBER_OF_IMAGES images and a skip of 2\n",
    "        positive, negative=gen_every_x_frames_skip(trainning,x=NUMBER_OF_IMAGES)\n",
    "        data_set_pos=data_set_pos+positive\n",
    "        data_set_neg=data_set_neg+negative\n",
    "    return data_set_pos,data_set_neg\n",
    "def test_data_set_gen():\n",
    "    data_set_pos=[]\n",
    "    data_set_neg=[]\n",
    "    for test in test_data_set:\n",
    "        # generate cases for 5 images and a skip of 2\n",
    "        positive, negative=gen_every_x_frames_skip(test, x=NUMBER_OF_IMAGES)\n",
    "        data_set_pos=data_set_pos+positive\n",
    "        data_set_neg=data_set_neg+negative\n",
    "    return data_set_pos,data_set_neg\n",
    "\n",
    "def pick_x_amount(data,x):\n",
    "    return random.sample(data,x)\n",
    "\n",
    "def open_images_prep_keras(posData, negData, limit, random=True):\n",
    "    # take positive and negative data and limit\n",
    "    if random:\n",
    "        posData=pick_x_amount(posData,limit)\n",
    "        negData=pick_x_amount(negData,limit)\n",
    "    else:\n",
    "        posData=posData[0:limit]\n",
    "        negData=negData[0:limit]\n",
    "    # image_paths Y\n",
    "    data_set=[]\n",
    "    for pos_images in posData:\n",
    "        image_paths=[]\n",
    "        for image in pos_images:\n",
    "            image_paths.append(image[1]+image[0])\n",
    "        xy=[image_paths,1]\n",
    "        data_set.append(xy)\n",
    "    for neg_images in negData:\n",
    "        image_paths=[]\n",
    "        for image in neg_images:\n",
    "            image_paths.append(image[1]+image[0])\n",
    "        xy=[image_paths,0]\n",
    "        data_set.append(xy)\n",
    "    data_set=np.array(data_set)\n",
    "    np.random.shuffle(data_set)\n",
    "    for data in data_set:\n",
    "        image_data={}\n",
    "        for i,image_path in enumerate(data[0]):\n",
    "            image_data[f\"input_{i}\"]=np.array(Image.open(image_path),dtype=np.float32)/255\n",
    "        yield (image_data,np.array(data[1],dtype=np.int8))\n",
    "\n",
    "def trainning_images_gen():\n",
    "    keras_trainning_data_set_pos, keras_trainning_data_set_neg= trainning_data_set_gen()\n",
    "    return open_images_prep_keras(keras_trainning_data_set_pos,keras_trainning_data_set_neg,10000)\n",
    "\n",
    "def test_images_gen():\n",
    "    keras_test_data_set_pos, keras_test_data_set_neg= test_data_set_gen()\n",
    "    return open_images_prep_keras(keras_test_data_set_pos,keras_test_data_set_neg,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(trainning_images_gen())\n",
    "trainning_data_set_gen()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_gen_inputs={}\n",
    "x_gen_inputs_shapes={}\n",
    "for i in range(NUMBER_OF_IMAGES):\n",
    "    x_gen_inputs[f\"input_{i}\"]=tf.float32\n",
    "    x_gen_inputs_shapes[f\"input_{i}\"]=tf.TensorShape([800,1920,3])\n",
    "xy_gen_inputs_output=(x_gen_inputs,tf.int8)\n",
    "xy_gen_inputs_output_shape=(x_gen_inputs_shapes,tf.TensorShape([]))\n",
    "trainning_images_gen_tensor=tf.data.Dataset.from_generator(\n",
    "    trainning_images_gen,\n",
    "    xy_gen_inputs_output,\n",
    "    xy_gen_inputs_output_shape\n",
    "    )\n",
    "\n",
    "test_images_gen_tensor=tf.data.Dataset.from_generator(\n",
    "    test_images_gen,\n",
    "    xy_gen_inputs_output,\n",
    "    xy_gen_inputs_output_shape\n",
    "    )\n",
    "training_dataset_with_batch_and_prefetch=trainning_images_gen_tensor.batch(20).prefetch(2)\n",
    "test_dataset_with_batch_and_prefetch=test_images_gen_tensor.batch(20).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert input to output\n",
    "def start_of_cnn(i):\n",
    "    image_input=tf.keras.layers.Input(shape=(800,1920,3),name=f\"input_{i}\")\n",
    "    x=tf.keras.layers.Conv2D(filters=10,kernel_size=[2,2],activation='relu',padding='valid')(image_input)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "    x=tf.keras.layers.Conv2D(filters=20,kernel_size=[2,2],activation='relu',padding='valid')(x)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "    x=tf.keras.layers.Conv2D(filters=40,kernel_size=[2,2],activation='relu',padding='valid')(x)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "    x=tf.keras.layers.Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='valid')(x)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "    x=tf.keras.layers.Conv2D(filters=160,kernel_size=[2,2],activation='relu',padding='valid')(x)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "    x=tf.keras.layers.Conv2D(filters=320,kernel_size=[2,2],activation='relu',padding='valid')(x)\n",
    "    x=tf.keras.layers.MaxPooling2D()(x)\n",
    "    x=tf.keras.layers.Dropout(.1)(x)\n",
    "\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    # x=tf.keras.Model(inputs=image_input,outputs=x) #(None, 48, 118, 25) \n",
    "    return image_input,x\n",
    "inputs=[]\n",
    "combined_layers=[]\n",
    "for i in range(NUMBER_OF_IMAGES):\n",
    "    input_cnn, combined_layer = start_of_cnn(i)\n",
    "    inputs.append(input_cnn)\n",
    "    combined_layers.append(combined_layer)\n",
    "\n",
    "combined=tf.keras.layers.concatenate(axis=1,inputs=combined_layers)\n",
    "x=tf.keras.layers.Dense(20, activation=\"relu\")(combined)\n",
    "x=tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "x=tf.keras.layers.Dense(1, activation=\"softmax\")(x)\n",
    "x=tf.keras.Model(inputs=inputs,outputs=x)\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "x.fit(training_dataset_with_batch_and_prefetch,validation_data=test_dataset_with_batch_and_prefetch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backwardsv2",
   "language": "python",
   "name": "backwardsv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}